{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ded417-481e-4fff-b3b6-8b52f090b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from itertools import accumulate, product\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "mpl.use(\"pgf\")\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"pgf.rcfonts\"] = False\n",
    "plt.rcParams[\"pgf.texsystem\"] = \"lualatex\"\n",
    "plt.rcParams[\"pgf.preamble\"] = \"\"\"\n",
    "\\\\usepackage{fontspec}\n",
    "\\\\usepackage[T1]{fontenc}\n",
    "\\\\usepackage[utf8]{inputenc}\n",
    "\\\\usepackage{unicode-math}\n",
    "\n",
    "\\defaultfontfeatures{\n",
    "    Extension = .otf,\n",
    "}\n",
    "\n",
    "\\\\setmainfont{HelveticaNeueLTStd}[\n",
    "    UprightFont=*-Roman,\n",
    "    ItalicFont=*-It,\n",
    "    BoldFont=*-Md,\n",
    "    BoldItalicFont=*-MdIt,\n",
    "    FontFace={xl}{n}{*-UltLt},\n",
    "    FontFace={xl}{it}{*-UltLtIt},\n",
    "    FontFace={l}{n}{*-Lt},\n",
    "    FontFace={l}{it}{*-LtIt},\n",
    "    FontFace={mb}{n}{*-Md},\n",
    "    FontFace={mb}{it}{*-MdIt},\n",
    "    FontFace={k}{n}{*-Blk},\n",
    "    FontFace={k}{it}{*-BlkIt},\n",
    "    Scale=0.9,\n",
    "]\n",
    "\\\\setsansfont{HelveticaNeueLTStd}[\n",
    "    UprightFont=*-Roman,\n",
    "    ItalicFont=*-It,\n",
    "    BoldFont=*-Md,\n",
    "    BoldItalicFont=*-MdIt,\n",
    "    FontFace={xl}{n}{*-UltLt},\n",
    "    FontFace={xl}{it}{*-UltLtIt},\n",
    "    FontFace={l}{n}{*-Lt},\n",
    "    FontFace={l}{it}{*-LtIt},\n",
    "    FontFace={mb}{n}{*-Md},\n",
    "    FontFace={mb}{it}{*-MdIt},\n",
    "    FontFace={k}{n}{*-Blk},\n",
    "    FontFace={k}{it}{*-BlkIt},\n",
    "    Scale=0.9,\n",
    "]\n",
    "\n",
    "\\\\setmathfont{latinmodern-math.otf}\n",
    "\\\\setmathfont[\n",
    "    range=\\\\mathup,\n",
    "    Scale=0.9,\n",
    "]{HelveticaNeueLTStd-Roman}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c99a71-b87d-4b55-b8b2-3d55249b382b",
   "metadata": {},
   "source": [
    "## Commonality math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cb2bc0-596f-46eb-a6bf-6c57121cb7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave(b: tuple[int, ...], a: tuple[int, ...]) -> tuple[int, ...]:\n",
    "    c = np.ones(len(a), dtype=int)\n",
    "    c[np.array(a, dtype=bool)] = b\n",
    "    return tuple(c)\n",
    "\n",
    "\n",
    "def commonality_polynomial(terms: tuple[int, ...]) -> list[tuple[tuple[int, ...], int]]:\n",
    "    return [\n",
    "        (\n",
    "            interleave(exponents, terms),\n",
    "            -1 if sum(exponents) % 2 == 0 else 1,\n",
    "        )\n",
    "        for exponents in product((0, 1), repeat=sum(terms))\n",
    "    ]\n",
    "\n",
    "\n",
    "def commonality_polynomials(n: int):\n",
    "    for terms in product((0, 1), repeat=n):\n",
    "        if sum(terms) > 0:\n",
    "            yield (\n",
    "                terms,\n",
    "                commonality_polynomial(terms),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0caf95e-1d0a-4914-a23a-30f4b1aa6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(v: tuple[int, ...], w: tuple[int, ...]):\n",
    "    n = len(v)\n",
    "    return sum(\n",
    "        0 if a == b else (10 if i == 0 else 1) for i, (a, b) in enumerate(zip(v, w))\n",
    "    )\n",
    "\n",
    "\n",
    "def traveling_salesman_sort(commonality):\n",
    "    v, _ = zip(*commonality)  # extract component vectors\n",
    "\n",
    "    adjacency = np.array([[weight(v_i, v_j) for v_j in v] for v_i in v])\n",
    "\n",
    "    graph = nx.from_numpy_array(adjacency)\n",
    "    cycle = nx.approximation.traveling_salesman_problem(graph, cycle=True)\n",
    "\n",
    "    for pos, i in enumerate(cycle):\n",
    "        if v[i][0] == 1:\n",
    "            break\n",
    "\n",
    "    path = cycle[pos:-1] + cycle[:pos]\n",
    "\n",
    "    return [commonality[i] for i in path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d490fa0-e6ae-4c9b-b298-92fb1e929c0f",
   "metadata": {},
   "source": [
    "## Load time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72a26e1-42ca-4fad-8951-7d3c3815ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\"resample\", \"smooth\", \"ica_aroma\", \"temporal_filter\"]\n",
    "\n",
    "variable_groups = [\"task\", \"ica_aroma_signal\", \"ica_aroma_noise\", \"motion\", \"wm_csf\", \"a_comp_cor\", \"global_signal\"]\n",
    "variable_group_patterns = dict(\n",
    "    ica_aroma_signal=[\n",
    "        r\"aroma_signal_[0-9]+\",\n",
    "    ],\n",
    "    ica_aroma_noise=[\n",
    "        r\"aroma_noise_[0-9]+\",\n",
    "    ],\n",
    "    motion=[\n",
    "        r\"framewise_displacement\",\n",
    "        r\"dvars\",\n",
    "        r\"std_dvars\",\n",
    "        r\"rmsd\",\n",
    "        r\"(trans|rot)_[xyz](_derivative1)?(_power2)?\",\n",
    "    ],\n",
    "    wm_csf=[\n",
    "        r\"(white_matter|csf)(_derivative1)?(_power2)?\",\n",
    "        r\"csf_wm\",\n",
    "    ],\n",
    "    a_comp_cor=[\n",
    "        r\"a_comp_cor_0[0-4]\",\n",
    "    ],\n",
    "    global_signal=[\n",
    "        r\"global_signal(_derivative1)?(_power2)?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa50783-2d87-4594-b4c1-5e91cfc453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_coordinate = (61, 15, 47)\n",
    "repetition_time = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e29e222-4cce-4f0f-a294-cc8463b96a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_file = \"data/sub-01_task-faces_run-01_feature-taskBased_desc-design_matrix.tsv\"\n",
    "\n",
    "confound_files = dict(\n",
    "    resample=\"data/merge_with_header.tsv\",\n",
    "    smooth=\"data/merge_with_header.tsv\",\n",
    "    ica_aroma=\"data/merge_with_header_regfilt.tsv\",\n",
    "    temporal_filter=\"data/merge_with_header_regfilt_bptf_addmean.tsv\",\n",
    ")\n",
    "\n",
    "image_files = dict(\n",
    "    resample=\"data/vol0000_xform-00000_merged_masked.nii.gz\",\n",
    "    smooth=\"data/vol0000_xform-00000_merged_masked_afni.nii.gz\",\n",
    "    ica_aroma=\"data/vol0000_xform-00000_merged_masked_afni_grandmeanscaled_regfilt.nii.gz\",\n",
    "    temporal_filter=\"data/vol0000_xform-00000_merged_masked_afni_grandmeanscaled_regfilt_bptf_addmean.nii.gz\",\n",
    ")\n",
    "\n",
    "need_to_scale = set([\"resample\", \"smooth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd32934-4a8f-4caf-92fc-4dbc3506ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct grand mean scaling factor\n",
    "\n",
    "unscaled = pd.read_table(\"data/confounds_expansion_desc-motion_outliers.tsv\").global_signal\n",
    "data_frame = pd.read_table(confound_files[\"resample\"])\n",
    "grand_mean_scaling_factor = (data_frame.global_signal / unscaled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ed89bb-ba32-4d17-ac86-e75fcfa53758",
   "metadata": {},
   "outputs": [],
   "source": [
    "design = pd.read_table(design_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e357b710-9535-4366-bf8a-9db0ec8153c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = dict()\n",
    "for step, image_file in image_files.items():\n",
    "    image = nib.load(image_file)\n",
    "    image_data[step] = image.dataobj[voxel_coordinate].astype(float)\n",
    "    if step in need_to_scale:\n",
    "        image_data[step] *= grand_mean_scaling_factor\n",
    "\n",
    "regressor_data = dict()\n",
    "for step, confound_file in confound_files.items():\n",
    "    regressor_data[step] = dict(\n",
    "        task=design,\n",
    "    )\n",
    "\n",
    "    data_frame = pd.read_table(confound_file)\n",
    "    data_frame = data_frame.sub(data_frame.mean())  # demean\n",
    "    \n",
    "    for variable_group, patterns in variable_group_patterns.items():\n",
    "        columns = [\n",
    "            column\n",
    "            for pattern in patterns\n",
    "            for column in data_frame.columns\n",
    "            if re.fullmatch(pattern, column) is not None\n",
    "        ]\n",
    "\n",
    "        regressor_data[step][variable_group] = data_frame[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93774d1-403f-49d1-917d-9108a5952680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for step in steps:\n",
    "    plt.plot(image_data[step])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc5291-db6f-477e-be03-a23aa3b90637",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59912fc-e633-4bad-a133-2865c95ad948",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(variable_groups)\n",
    "m = len(steps)\n",
    "\n",
    "p = list(commonality_polynomials(n))\n",
    "\n",
    "var = np.std\n",
    "var_label = \"$\\\\sqrt{\\\\text{Variance}}$ [AU]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae882db6-0ec7-45b9-a5bd-16728177ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(y, x):\n",
    "    return (\n",
    "        sm.OLS(\n",
    "            endog=y,\n",
    "            exog=np.hstack([np.ones([y.size, 1]), x.fillna(0).values]),\n",
    "        )\n",
    "        .fit()\n",
    "        .predict()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9ad1eb-0c0c-4ac2-ad1f-f5f5fa5aff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = dict()\n",
    "for step in steps:\n",
    "    y = np.copy(image_data[step])\n",
    "    y -= y.mean()\n",
    "    y_dict[step] = y\n",
    "\n",
    "rsquareds_dict = dict()\n",
    "for step in steps:\n",
    "    y = y_dict[step] \n",
    "    \n",
    "    rsquareds_dict[step] = {\n",
    "        is_selected: sm.OLS(\n",
    "            endog=y,\n",
    "            exog=np.hstack(\n",
    "                [\n",
    "                    np.ones([y.size, 1]),  # intercept\n",
    "                    *[\n",
    "                        regressor_data[step][variable_groups[i]].fillna(0).values\n",
    "                        for i in range(len(variable_groups))\n",
    "                        if is_selected[i] == 1\n",
    "                    ],\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        .fit()\n",
    "        .rsquared\n",
    "        for is_selected in product((0, 1), repeat=len(variable_groups))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20decaa4-959e-4a99-bac0-7ade2a971d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_variance = max(var(y) for y in y_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d49322-0047-4719-8911-68b0e7569ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "\n",
    "def circled(s):\n",
    "    return \"\\\\raisebox{.5pt}{\\\\textcircled{\\\\raisebox{-.9pt} {\" + str(s) + \"}}}\"\n",
    "\n",
    "step_labels = dict(\n",
    "    resample=f\"{circled(0)} \\\\textbf{{Resampled image}}\",\n",
    "    smooth=f\"{circled(1)} \\\\textbf{{Post smoothing}}\",\n",
    "    ica_aroma=f\"{circled(2)} \\\\textbf{{Post ICA-AROMA component regression}}\",\n",
    "    temporal_filter=f\"{circled(3)} \\\\textbf{{Post temporal filter (high-pass only)}}\",\n",
    ")\n",
    "\n",
    "variable_group_labels = dict(\n",
    "    task=\"Task\",\n",
    "    ica_aroma_signal=\"ICA-AROMA\\nSignal\",\n",
    "    ica_aroma_noise=\"ICA-AROMA\\nNoise\",\n",
    "    motion=\"Motion\",\n",
    "    wm_csf=\"WM/CSF\",\n",
    "    global_signal=\"Global signal\",\n",
    "    a_comp_cor=\"aCompCor\",\n",
    "    auto_corr=\"Autocorrelation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51da8fef-b8e6-44e9-bee5-47b8af7ab9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helpers\n",
    "\n",
    "time_formatter = ticker.FuncFormatter(\n",
    "    lambda seconds, x: time.strftime(\"%M:%S\", time.gmtime(seconds))\n",
    ")\n",
    "\n",
    "cmap = cm.get_cmap(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a7e8c07-91d0-464b-8c8c-85b8d8056cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    m,\n",
    "    2,\n",
    "    figsize=(10, 12),\n",
    "    gridspec_kw=dict(width_ratios=[0.7, 1]),\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0, 0].get_shared_y_axes().join(*[axs[k, 0] for k in range(m)])\n",
    "axs[0, 1].get_shared_x_axes().join(*[axs[k, 1] for k in range(m)])\n",
    "\n",
    "for k, step in enumerate(steps):\n",
    "    y = y_dict[step]\n",
    "    rsquareds = rsquareds_dict[step]\n",
    "\n",
    "    commonality = [\n",
    "        (\n",
    "            component,\n",
    "            sum(weight * rsquareds[term] for term, weight in terms),\n",
    "        )\n",
    "        for component, terms in p\n",
    "    ]\n",
    "\n",
    "    axs[k, 0].set_title(step_labels[step], loc=\"left\", pad=10)\n",
    "\n",
    "    axs[k, 0].set_yticks([])\n",
    "    axs[k, 0].grid(False)\n",
    "    axs[k, 0].xaxis.set_major_formatter(time_formatter)\n",
    "    axs[k, 0].set(xlabel=\"Time\")\n",
    "\n",
    "    axs[k, 1].set_yticks([i - 0.125 for i in range(-1, n)])\n",
    "    axs[k, 1].set_yticklabels(\n",
    "        [\"Total\"] + [variable_group_labels[key] for key in reversed(variable_groups)],\n",
    "        linespacing=0.9,\n",
    "    )\n",
    "    axs[k, 1].yaxis.tick_right()\n",
    "    axs[k, 1].set(xlabel=var_label)\n",
    "\n",
    "    for key in [\"task\"]:\n",
    "        y_hat = predict(y, regressor_data[step][key])\n",
    "\n",
    "        axs[k, 0].plot(\n",
    "            np.arange(len(y)) * repetition_time,\n",
    "            y_hat,\n",
    "            \"o--\",\n",
    "            color=(\n",
    "                *cmap(variable_groups.index(key))[:3],\n",
    "                0.75,  # opacity\n",
    "            ),\n",
    "            linewidth=0.5,\n",
    "            markersize=1,\n",
    "        )\n",
    "\n",
    "    axs[k, 0].plot(\n",
    "        np.arange(len(y)) * repetition_time,\n",
    "        y,\n",
    "        \"o-\",\n",
    "        color=\"black\",\n",
    "        linewidth=0.5,\n",
    "        markersize=1,\n",
    "    )\n",
    "\n",
    "    negative_commonality = sum(\n",
    "        proportion for _, proportion in commonality if proportion < 0\n",
    "    )\n",
    "    variance = var(y)\n",
    "\n",
    "    commonality_sorted = traveling_salesman_sort(\n",
    "        [\n",
    "            (component, proportion)\n",
    "            for component, proportion in commonality\n",
    "            if not np.isclose(proportion, 0) and not proportion < 0\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for i in range(n):\n",
    "        intervals = []\n",
    "\n",
    "        x = 0\n",
    "        for component, proportion in commonality_sorted:\n",
    "            if proportion < 0:\n",
    "                continue\n",
    "\n",
    "            x += proportion\n",
    "\n",
    "            if component[i] != 1:\n",
    "                continue  # not relevant for this row\n",
    "\n",
    "            intervals.append(((x - proportion) * variance, proportion * variance))\n",
    "\n",
    "        axs[k, 1].broken_barh(\n",
    "            intervals, (n - i - 1.5, 0.75), color=cmap(i), capstyle=\"butt\"\n",
    "        )\n",
    "\n",
    "        x_max = max(map(sum, intervals))\n",
    "\n",
    "        if i == 0:\n",
    "            axs[k, 1].axvline(0, color=cmap(i), linewidth=0.5)\n",
    "            axs[k, 1].axvline(x_max, color=cmap(i), linewidth=0.5)\n",
    "\n",
    "        rsquared = rsquareds[tuple(1 if j == i else 0 for j in range(n))]\n",
    "\n",
    "        axs[k, 1].text(\n",
    "            x_max + 0.05 * maximum_variance,\n",
    "            n - i - 1.175,\n",
    "            f\"{rsquared * 100:.0f}%\",  # ({suppression * 100:.0f}%)\",\n",
    "            ha=\"left\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "            backgroundcolor=\"white\",\n",
    "        )\n",
    "\n",
    "    intervals = [\n",
    "        (0, variance / (1 + negative_commonality)),\n",
    "    ]\n",
    "    axs[k, 1].broken_barh(intervals, (-1.5, 0.75), color=(0.8, 0.8, 0.8, 1.0))\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.35, top=0.95, bottom=0.05, right=0.91)\n",
    "\n",
    "plt.savefig(\"confs.pdf\", backend=\"pgf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
