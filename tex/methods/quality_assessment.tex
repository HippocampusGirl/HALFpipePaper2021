\subsection{Quality assessment}\label{sec:qamethods}

Assessing the quality of data and preprocessing is a laborious undertaking and often done manually. Efforts to automate this process, either through predefined thresholds of image quality features \parencite{alfaroalmagro2018} or machine learning \parencite{esteban2017} are not yet ready to replace the eyes of a trained researcher checking the data. However, various approaches make this process easier. First, rather than viewing three-dimensional neuroimaging files directly, generating and viewing reports containing two-dimensional images offers a significant time savings. Second, tools such as \soft{slicesdir} (in \soft{FSL}), \soft{fMRIPrep}, and \soft{MRIQC} generate HTML files that contain multiple report images and can be explored in a web browser. \soft{MRIQC} also provides an interactive widget to rate the quality of each image \parencite{esteban2019b}.

In \soft{HALFpipe}, we use a fixed set of processing steps for quality assessment. While \soft{slicesdir} allows the researcher to easily compare the same image type across different subjects, it cannot be used to generate reports for all types of images. By contrast, \soft{fMRIPrep}/\soft{MRIQC} HTML files have a broad range of information and quality report images included, but one HTML file is always specific to one subject. As such, examining multiple processing steps in many subjects can be cumbersome.

To overcome these issues, \soft{HALFpipe} provides an interactive web app that is contained in a single HTML file. The app dynamically loads reports with images, and can handle datasets up to thousands of images without a performance penalty. The images can be sorted both by subject, as is done by \soft{fMRIPrep}/\soft{MRIQC}, or by image type, as is done in \soft{slicesdir}. Each image can be rated as either good, uncertain, or bad. Predefined logic automatically converts these ratings into inclusion/exclusion decisions for \soft{HALFpipe}'s group statistics. In addition, tagging images as uncertain enables users to efficiently retrieve and discuss these with a colleague or collaborator, after which a definitive decision on image quality can be made.
